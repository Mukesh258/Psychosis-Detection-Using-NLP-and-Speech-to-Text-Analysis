{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Psychosis Detection Dataset Exploration\n",
        "\n",
        "This notebook explores the synthetic psychosis dataset used for training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "# Add src to path\n",
        "sys.path.append(str(Path('.').parent / 'src'))\n",
        "\n",
        "from data_loader import load_dataset\n",
        "from preprocess import preprocess_batch\n",
        "from features import FeatureExtractor\n",
        "\n",
        "# Set style\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data\n",
        "data_path = Path('..') / 'data' / 'synthetic_psychosis_data.csv'\n",
        "df = load_dataset(str(data_path))\n",
        "\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"\\nLabel distribution:\")\n",
        "print(df['label'].value_counts())\n",
        "print(f\"\\nLabel distribution (%):\")\n",
        "print(df['label'].value_counts(normalize=True) * 100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset Statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preprocess text\n",
        "df['text_processed'] = preprocess_batch(df['text'].values)\n",
        "\n",
        "# Calculate text statistics\n",
        "df['text_length'] = df['text_processed'].str.len()\n",
        "df['word_count'] = df['text_processed'].str.split().str.len()\n",
        "\n",
        "# Group by label\n",
        "stats = df.groupby('label').agg({\n",
        "    'text_length': ['mean', 'std', 'min', 'max'],\n",
        "    'word_count': ['mean', 'std', 'min', 'max']\n",
        "})\n",
        "\n",
        "print(\"Text Statistics by Label:\")\n",
        "print(stats)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Label distribution\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Count plot\n",
        "df['label'].value_counts().plot(kind='bar', ax=axes[0], color=['#10b981', '#ef4444'])\n",
        "axes[0].set_title('Label Distribution')\n",
        "axes[0].set_xlabel('Label')\n",
        "axes[0].set_ylabel('Count')\n",
        "axes[0].tick_params(axis='x', rotation=0)\n",
        "\n",
        "# Text length distribution\n",
        "df.boxplot(column='text_length', by='label', ax=axes[1])\n",
        "axes[1].set_title('Text Length by Label')\n",
        "axes[1].set_xlabel('Label')\n",
        "axes[1].set_ylabel('Text Length (characters)')\n",
        "plt.suptitle('')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Word count distribution\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "for label in df['label'].unique():\n",
        "    subset = df[df['label'] == label]\n",
        "    ax.hist(subset['word_count'], alpha=0.6, label=label, bins=20)\n",
        "\n",
        "ax.set_title('Word Count Distribution by Label')\n",
        "ax.set_xlabel('Word Count')\n",
        "ax.set_ylabel('Frequency')\n",
        "ax.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract features\n",
        "extractor = FeatureExtractor()\n",
        "\n",
        "print(\"Extracting features (this may take a moment)...\")\n",
        "features_list = extractor.extract_batch_features(df['text_processed'].values)\n",
        "\n",
        "# Convert to DataFrame\n",
        "features_df = pd.DataFrame(features_list)\n",
        "features_df['label'] = df['label'].values\n",
        "\n",
        "print(\"\\nFeature Statistics:\")\n",
        "print(features_df.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare features by label\n",
        "feature_cols = ['negation_count', 'pronoun_count', 'negative_emotions', 'positive_emotions']\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, col in enumerate(feature_cols):\n",
        "    if col in features_df.columns:\n",
        "        features_df.boxplot(column=col, by='label', ax=axes[i])\n",
        "        axes[i].set_title(f'{col.replace(\"_\", \" \").title()} by Label')\n",
        "        axes[i].set_xlabel('Label')\n",
        "        axes[i].set_ylabel(col.replace('_', ' ').title())\n",
        "\n",
        "plt.suptitle('')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sample Texts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show sample texts from each class\n",
        "print(\"Sample Psychotic-like Texts:\")\n",
        "print(\"=\" * 80)\n",
        "for idx, row in df[df['label'] == 'psychotic-like'].head(3).iterrows():\n",
        "    print(f\"\\n{row['text'][:200]}...\")\n",
        "\n",
        "print(\"\\n\\nSample Normal Texts:\")\n",
        "print(\"=\" * 80)\n",
        "for idx, row in df[df['label'] == 'normal'].head(3).iterrows():\n",
        "    print(f\"\\n{row['text'][:200]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook provides basic exploration of the dataset. Key insights:\n",
        "- Dataset size and label distribution\n",
        "- Text length and word count statistics\n",
        "- Feature distributions\n",
        "- Sample texts from each class\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
